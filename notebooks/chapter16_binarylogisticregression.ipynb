{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Testing with Out-of-Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/yutanagano/Projects/nnfs')\n",
    "os.chdir('/home/yutanagano/Projects/nnfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "import nnn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=1000, classes=3)\n",
    "\n",
    "# Create the necessary layers\n",
    "dense1 = nnn.layer.Dense(n_inputs=2,n_neurons=32,l2w=5e-4,l2b=5e-4)\n",
    "relu = nnn.activation.Relu()\n",
    "dropout = nnn.layer.Dropout(0.1)\n",
    "dense2 = nnn.layer.Dense(n_inputs=32,n_neurons=3)\n",
    "activation_loss = nnn.loss.SoftmaxWithCategoricalCrossentropy()\n",
    "\n",
    "# Create the optimiser\n",
    "optimiser = nnn.optimiser.Adam(learning_rate=0.005)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.313, loss: 1.099, (data_loss: 1.0986073017120361, reg_loss: 2.962743164971471e-06), lr: 0.005\n",
      "epoch: 100, acc: 0.484, loss: 1.007, (data_loss: 1.0040286779403687, reg_loss: 0.0029602911323308944), lr: 0.005\n",
      "epoch: 200, acc: 0.558, loss: 0.930, (data_loss: 0.9237253665924072, reg_loss: 0.006308419525623322), lr: 0.005\n",
      "epoch: 300, acc: 0.581, loss: 0.908, (data_loss: 0.9003919363021851, reg_loss: 0.007582645297050476), lr: 0.005\n",
      "epoch: 400, acc: 0.604, loss: 0.864, (data_loss: 0.8549649119377136, reg_loss: 0.009118103623390198), lr: 0.005\n",
      "epoch: 500, acc: 0.636, loss: 0.820, (data_loss: 0.8092005848884583, reg_loss: 0.010598394632339478), lr: 0.005\n",
      "epoch: 600, acc: 0.628, loss: 0.825, (data_loss: 0.81386798620224, reg_loss: 0.01158379316329956), lr: 0.005\n",
      "epoch: 700, acc: 0.637, loss: 0.810, (data_loss: 0.7976713180541992, reg_loss: 0.012417269706726075), lr: 0.005\n",
      "epoch: 800, acc: 0.654, loss: 0.792, (data_loss: 0.7788466811180115, reg_loss: 0.01268672800064087), lr: 0.005\n",
      "epoch: 900, acc: 0.642, loss: 0.792, (data_loss: 0.7787317633628845, reg_loss: 0.013060928344726563), lr: 0.005\n",
      "epoch: 1000, acc: 0.644, loss: 0.797, (data_loss: 0.7830378413200378, reg_loss: 0.013879112482070924), lr: 0.005\n",
      "epoch: 1100, acc: 0.651, loss: 0.769, (data_loss: 0.7548816800117493, reg_loss: 0.014561871051788331), lr: 0.005\n",
      "epoch: 1200, acc: 0.649, loss: 0.786, (data_loss: 0.7711849212646484, reg_loss: 0.015192890644073488), lr: 0.005\n",
      "epoch: 1300, acc: 0.644, loss: 0.792, (data_loss: 0.7762154936790466, reg_loss: 0.01537310552597046), lr: 0.005\n",
      "epoch: 1400, acc: 0.668, loss: 0.763, (data_loss: 0.7466614842414856, reg_loss: 0.016029447078704833), lr: 0.005\n",
      "epoch: 1500, acc: 0.663, loss: 0.761, (data_loss: 0.7448062896728516, reg_loss: 0.01611570429801941), lr: 0.005\n",
      "epoch: 1600, acc: 0.661, loss: 0.777, (data_loss: 0.7602753043174744, reg_loss: 0.016485244274139405), lr: 0.005\n",
      "epoch: 1700, acc: 0.673, loss: 0.775, (data_loss: 0.7585727572441101, reg_loss: 0.01665412616729736), lr: 0.005\n",
      "epoch: 1800, acc: 0.678, loss: 0.767, (data_loss: 0.7501782178878784, reg_loss: 0.01661926507949829), lr: 0.005\n",
      "epoch: 1900, acc: 0.678, loss: 0.754, (data_loss: 0.7371788620948792, reg_loss: 0.016934509277343752), lr: 0.005\n",
      "epoch: 2000, acc: 0.675, loss: 0.739, (data_loss: 0.7219842076301575, reg_loss: 0.01697464847564697), lr: 0.005\n",
      "epoch: 2100, acc: 0.676, loss: 0.754, (data_loss: 0.7371649742126465, reg_loss: 0.016919763565063476), lr: 0.005\n",
      "epoch: 2200, acc: 0.668, loss: 0.765, (data_loss: 0.7476570010185242, reg_loss: 0.017083692550659182), lr: 0.005\n",
      "epoch: 2300, acc: 0.674, loss: 0.747, (data_loss: 0.729423999786377, reg_loss: 0.017151816368103028), lr: 0.005\n",
      "epoch: 2400, acc: 0.669, loss: 0.759, (data_loss: 0.7422729730606079, reg_loss: 0.017160537719726563), lr: 0.005\n",
      "epoch: 2500, acc: 0.667, loss: 0.756, (data_loss: 0.7384658455848694, reg_loss: 0.01717550230026245), lr: 0.005\n",
      "epoch: 2600, acc: 0.662, loss: 0.736, (data_loss: 0.7188076376914978, reg_loss: 0.01723362636566162), lr: 0.005\n",
      "epoch: 2700, acc: 0.675, loss: 0.748, (data_loss: 0.7307965755462646, reg_loss: 0.017248838424682618), lr: 0.005\n",
      "epoch: 2800, acc: 0.671, loss: 0.759, (data_loss: 0.7418529987335205, reg_loss: 0.017198644638061523), lr: 0.005\n",
      "epoch: 2900, acc: 0.676, loss: 0.768, (data_loss: 0.7507666945457458, reg_loss: 0.017256006717681883), lr: 0.005\n",
      "epoch: 3000, acc: 0.676, loss: 0.762, (data_loss: 0.7443429231643677, reg_loss: 0.017380144119262697), lr: 0.005\n",
      "epoch: 3100, acc: 0.684, loss: 0.747, (data_loss: 0.7302585244178772, reg_loss: 0.017172133445739746), lr: 0.005\n",
      "epoch: 3200, acc: 0.668, loss: 0.748, (data_loss: 0.730663001537323, reg_loss: 0.017056541919708252), lr: 0.005\n",
      "epoch: 3300, acc: 0.690, loss: 0.748, (data_loss: 0.7307833433151245, reg_loss: 0.017297859191894534), lr: 0.005\n",
      "epoch: 3400, acc: 0.678, loss: 0.749, (data_loss: 0.731645405292511, reg_loss: 0.017072202682495118), lr: 0.005\n",
      "epoch: 3500, acc: 0.679, loss: 0.748, (data_loss: 0.730816662311554, reg_loss: 0.017174516677856445), lr: 0.005\n",
      "epoch: 3600, acc: 0.696, loss: 0.738, (data_loss: 0.7208419442176819, reg_loss: 0.0169372501373291), lr: 0.005\n",
      "epoch: 3700, acc: 0.683, loss: 0.752, (data_loss: 0.7344442009925842, reg_loss: 0.01709933853149414), lr: 0.005\n",
      "epoch: 3800, acc: 0.687, loss: 0.748, (data_loss: 0.730861246585846, reg_loss: 0.017116724967956545), lr: 0.005\n",
      "epoch: 3900, acc: 0.690, loss: 0.743, (data_loss: 0.7258442640304565, reg_loss: 0.017323144912719725), lr: 0.005\n",
      "epoch: 4000, acc: 0.670, loss: 0.748, (data_loss: 0.7306057214736938, reg_loss: 0.017174779891967775), lr: 0.005\n",
      "epoch: 4100, acc: 0.664, loss: 0.797, (data_loss: 0.779556393623352, reg_loss: 0.017027786254882812), lr: 0.005\n",
      "epoch: 4200, acc: 0.677, loss: 0.733, (data_loss: 0.7157717943191528, reg_loss: 0.017083045959472656), lr: 0.005\n",
      "epoch: 4300, acc: 0.670, loss: 0.781, (data_loss: 0.7642592787742615, reg_loss: 0.017152485847473142), lr: 0.005\n",
      "epoch: 4400, acc: 0.660, loss: 0.756, (data_loss: 0.7392428517341614, reg_loss: 0.017055543899536132), lr: 0.005\n",
      "epoch: 4500, acc: 0.668, loss: 0.752, (data_loss: 0.7353661060333252, reg_loss: 0.017092752456665042), lr: 0.005\n",
      "epoch: 4600, acc: 0.678, loss: 0.734, (data_loss: 0.71755450963974, reg_loss: 0.01692720603942871), lr: 0.005\n",
      "epoch: 4700, acc: 0.662, loss: 0.734, (data_loss: 0.7169620990753174, reg_loss: 0.01704943370819092), lr: 0.005\n",
      "epoch: 4800, acc: 0.676, loss: 0.741, (data_loss: 0.7242432236671448, reg_loss: 0.017221103191375733), lr: 0.005\n",
      "epoch: 4900, acc: 0.671, loss: 0.762, (data_loss: 0.7450808882713318, reg_loss: 0.016960990905761718), lr: 0.005\n",
      "epoch: 5000, acc: 0.682, loss: 0.752, (data_loss: 0.7351884841918945, reg_loss: 0.016781455516815185), lr: 0.005\n",
      "epoch: 5100, acc: 0.670, loss: 0.752, (data_loss: 0.7355327010154724, reg_loss: 0.016955867290496827), lr: 0.005\n",
      "epoch: 5200, acc: 0.671, loss: 0.750, (data_loss: 0.7328131794929504, reg_loss: 0.016927037239074707), lr: 0.005\n",
      "epoch: 5300, acc: 0.664, loss: 0.763, (data_loss: 0.7457209229469299, reg_loss: 0.016968578338623048), lr: 0.005\n",
      "epoch: 5400, acc: 0.675, loss: 0.724, (data_loss: 0.7074466347694397, reg_loss: 0.016785130500793458), lr: 0.005\n",
      "epoch: 5500, acc: 0.664, loss: 0.751, (data_loss: 0.7346023917198181, reg_loss: 0.01675224781036377), lr: 0.005\n",
      "epoch: 5600, acc: 0.670, loss: 0.774, (data_loss: 0.7572877407073975, reg_loss: 0.017109450340270997), lr: 0.005\n",
      "epoch: 5700, acc: 0.673, loss: 0.735, (data_loss: 0.7184951305389404, reg_loss: 0.016886325836181642), lr: 0.005\n",
      "epoch: 5800, acc: 0.683, loss: 0.742, (data_loss: 0.7249250411987305, reg_loss: 0.016990408420562743), lr: 0.005\n",
      "epoch: 5900, acc: 0.689, loss: 0.751, (data_loss: 0.7343353629112244, reg_loss: 0.016853692054748536), lr: 0.005\n",
      "epoch: 6000, acc: 0.672, loss: 0.759, (data_loss: 0.7426238656044006, reg_loss: 0.01686176538467407), lr: 0.005\n",
      "epoch: 6100, acc: 0.689, loss: 0.728, (data_loss: 0.7113348245620728, reg_loss: 0.01695692825317383), lr: 0.005\n",
      "epoch: 6200, acc: 0.674, loss: 0.775, (data_loss: 0.7584207653999329, reg_loss: 0.01697733688354492), lr: 0.005\n",
      "epoch: 6300, acc: 0.669, loss: 0.755, (data_loss: 0.737773597240448, reg_loss: 0.016870713233947753), lr: 0.005\n",
      "epoch: 6400, acc: 0.665, loss: 0.734, (data_loss: 0.7173441648483276, reg_loss: 0.016690180778503417), lr: 0.005\n",
      "epoch: 6500, acc: 0.678, loss: 0.722, (data_loss: 0.7047664523124695, reg_loss: 0.016786273002624513), lr: 0.005\n",
      "epoch: 6600, acc: 0.671, loss: 0.748, (data_loss: 0.7314114570617676, reg_loss: 0.01664835262298584), lr: 0.005\n",
      "epoch: 6700, acc: 0.666, loss: 0.751, (data_loss: 0.7341046333312988, reg_loss: 0.01690348720550537), lr: 0.005\n",
      "epoch: 6800, acc: 0.678, loss: 0.737, (data_loss: 0.7202181816101074, reg_loss: 0.016798580646514894), lr: 0.005\n",
      "epoch: 6900, acc: 0.684, loss: 0.725, (data_loss: 0.7080496549606323, reg_loss: 0.016738918304443358), lr: 0.005\n",
      "epoch: 7000, acc: 0.668, loss: 0.760, (data_loss: 0.7434086799621582, reg_loss: 0.016581461906433108), lr: 0.005\n",
      "epoch: 7100, acc: 0.661, loss: 0.757, (data_loss: 0.7400209903717041, reg_loss: 0.01653901767730713), lr: 0.005\n",
      "epoch: 7200, acc: 0.669, loss: 0.742, (data_loss: 0.7250333428382874, reg_loss: 0.016896125316619874), lr: 0.005\n",
      "epoch: 7300, acc: 0.682, loss: 0.776, (data_loss: 0.7588580846786499, reg_loss: 0.016663871765136718), lr: 0.005\n",
      "epoch: 7400, acc: 0.679, loss: 0.753, (data_loss: 0.7366076111793518, reg_loss: 0.016751385688781737), lr: 0.005\n",
      "epoch: 7500, acc: 0.670, loss: 0.759, (data_loss: 0.7420517802238464, reg_loss: 0.016752130031585696), lr: 0.005\n",
      "epoch: 7600, acc: 0.679, loss: 0.750, (data_loss: 0.7333266735076904, reg_loss: 0.016666107177734375), lr: 0.005\n",
      "epoch: 7700, acc: 0.661, loss: 0.743, (data_loss: 0.7265076637268066, reg_loss: 0.016682079315185547), lr: 0.005\n",
      "epoch: 7800, acc: 0.681, loss: 0.733, (data_loss: 0.7161660194396973, reg_loss: 0.016679063320159913), lr: 0.005\n",
      "epoch: 7900, acc: 0.668, loss: 0.753, (data_loss: 0.7364987134933472, reg_loss: 0.01685105276107788), lr: 0.005\n",
      "epoch: 8000, acc: 0.685, loss: 0.726, (data_loss: 0.7097207903862, reg_loss: 0.01658205509185791), lr: 0.005\n",
      "epoch: 8100, acc: 0.682, loss: 0.761, (data_loss: 0.7437330484390259, reg_loss: 0.01692325210571289), lr: 0.005\n",
      "epoch: 8200, acc: 0.686, loss: 0.721, (data_loss: 0.7041399478912354, reg_loss: 0.016626402378082276), lr: 0.005\n",
      "epoch: 8300, acc: 0.668, loss: 0.744, (data_loss: 0.7274799942970276, reg_loss: 0.01649055004119873), lr: 0.005\n",
      "epoch: 8400, acc: 0.660, loss: 0.730, (data_loss: 0.7136088609695435, reg_loss: 0.016385397911071777), lr: 0.005\n",
      "epoch: 8500, acc: 0.682, loss: 0.757, (data_loss: 0.7398399114608765, reg_loss: 0.01699350643157959), lr: 0.005\n",
      "epoch: 8600, acc: 0.679, loss: 0.762, (data_loss: 0.7451168894767761, reg_loss: 0.016680382728576658), lr: 0.005\n",
      "epoch: 8700, acc: 0.670, loss: 0.750, (data_loss: 0.7338317036628723, reg_loss: 0.016269604682922365), lr: 0.005\n",
      "epoch: 8800, acc: 0.679, loss: 0.747, (data_loss: 0.7302454710006714, reg_loss: 0.016693652629852295), lr: 0.005\n",
      "epoch: 8900, acc: 0.667, loss: 0.739, (data_loss: 0.7227016687393188, reg_loss: 0.01675854206085205), lr: 0.005\n",
      "epoch: 9000, acc: 0.680, loss: 0.748, (data_loss: 0.7315583229064941, reg_loss: 0.016546969413757325), lr: 0.005\n",
      "epoch: 9100, acc: 0.691, loss: 0.731, (data_loss: 0.7143750786781311, reg_loss: 0.01638214635848999), lr: 0.005\n",
      "epoch: 9200, acc: 0.674, loss: 0.755, (data_loss: 0.7382733821868896, reg_loss: 0.01668360757827759), lr: 0.005\n",
      "epoch: 9300, acc: 0.680, loss: 0.731, (data_loss: 0.7148807048797607, reg_loss: 0.016567435264587402), lr: 0.005\n",
      "epoch: 9400, acc: 0.666, loss: 0.754, (data_loss: 0.7373809218406677, reg_loss: 0.016472752571105958), lr: 0.005\n",
      "epoch: 9500, acc: 0.676, loss: 0.733, (data_loss: 0.716440737247467, reg_loss: 0.016477384567260743), lr: 0.005\n",
      "epoch: 9600, acc: 0.668, loss: 0.770, (data_loss: 0.7540236115455627, reg_loss: 0.01625175619125366), lr: 0.005\n",
      "epoch: 9700, acc: 0.668, loss: 0.735, (data_loss: 0.7184329628944397, reg_loss: 0.01624960374832153), lr: 0.005\n",
      "epoch: 9800, acc: 0.664, loss: 0.772, (data_loss: 0.7558243870735168, reg_loss: 0.016262776851654052), lr: 0.005\n",
      "epoch: 9900, acc: 0.671, loss: 0.737, (data_loss: 0.7208060026168823, reg_loss: 0.0164277925491333), lr: 0.005\n",
      "epoch: 10000, acc: 0.680, loss: 0.730, (data_loss: 0.7135042548179626, reg_loss: 0.016684361934661867), lr: 0.005\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10001):\n",
    "    # Forward pass\n",
    "    output = dense1.forward(X)\n",
    "    output = relu.forward(output)\n",
    "    output = dropout.forward(output)\n",
    "    output = dense2.forward(output)\n",
    "\n",
    "    # Calculate the network's current loss\n",
    "    data_loss = activation_loss.forward(output, y)\n",
    "    reg_loss = activation_loss.categoricalcrossentropy.regularsiation_loss(dense1) +\\\n",
    "        activation_loss.categoricalcrossentropy.regularsiation_loss(dense2)\n",
    "    loss = data_loss + reg_loss\n",
    "\n",
    "    # Calculate accuracy\n",
    "    predictions = np.argmax(output,axis=1)\n",
    "    if len(y.shape) == 2: y = np.argmax(y,axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    # Print accuracy\n",
    "    if not epoch % 100: print(\n",
    "        f\"epoch: {epoch}, acc: {accuracy:.3f}, loss: {loss:.3f}, \"\n",
    "        f\"(data_loss: {data_loss}, reg_loss: {reg_loss}), \"\n",
    "        f\"lr: {optimiser.current_learning_rate}\"\n",
    "    )\n",
    "\n",
    "    # Backward pass\n",
    "    activation_loss.backward(activation_loss.outputs, y)\n",
    "    dense2.backward(activation_loss.dinputs)\n",
    "    dropout.backward(dense2.dinputs)\n",
    "    relu.backward(dropout.dinputs)\n",
    "    dense1.backward(relu.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimiser.pre_update_params()\n",
    "    optimiser.update_params(dense1)\n",
    "    optimiser.update_params(dense2)\n",
    "    optimiser.post_update_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation data set\n",
    "X_test, y_test = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass on validation set\n",
    "output = dense1.forward(X_test)\n",
    "output = relu.forward(output)\n",
    "output = dense2.forward(output)\n",
    "\n",
    "# Calculate validation loss\n",
    "loss = activation_loss.forward(output, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.737, loss: 0.703\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "predictions = np.argmax(output, axis=1)\n",
    "if len(y_test.shape) == 2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f\"validation, acc: {accuracy:.3f}, loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d485a98a36d7387b9a90aa3c793ce7a86a2239fa29b78a2ccbe0584c0791300d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
