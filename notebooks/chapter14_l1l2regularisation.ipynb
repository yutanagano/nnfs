{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11: Testing with Out-of-Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/home/yutanagano/Projects/nnfs')\n",
    "os.chdir('/home/yutanagano/Projects/nnfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "import nnn\n",
    "\n",
    "nnfs.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "\n",
    "# Create the necessary layers\n",
    "dense1 = nnn.layer.Dense(n_inputs=2,n_neurons=64,l2w=5e-4,l2b=5e-4)\n",
    "relu = nnn.activation.Relu()\n",
    "dense2 = nnn.layer.Dense(n_inputs=64,n_neurons=3)\n",
    "activation_loss = nnn.loss.SoftmaxWithCategoricalCrossentropy()\n",
    "\n",
    "# Create the optimiser\n",
    "optimiser = nnn.optimiser.Adam(learning_rate=0.01, decay=1e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.360, loss: 1.099, (data_loss: 1.098594307899475, reg_loss: 6.1487173661589625e-06), lr: 0.01\n",
      "epoch: 100, acc: 0.713, loss: 0.765, (data_loss: 0.7357513308525085, reg_loss: 0.029340030431747436), lr: 0.009990109791306606\n",
      "epoch: 200, acc: 0.807, loss: 0.595, (data_loss: 0.5536873936653137, reg_loss: 0.040994081497192386), lr: 0.009980139522350523\n",
      "epoch: 300, acc: 0.833, loss: 0.513, (data_loss: 0.46612802147865295, reg_loss: 0.04675359606742859), lr: 0.009970189134487882\n",
      "epoch: 400, acc: 0.807, loss: 0.508, (data_loss: 0.4565824270248413, reg_loss: 0.051665717363357545), lr: 0.009960258568312435\n",
      "epoch: 500, acc: 0.870, loss: 0.433, (data_loss: 0.3764248788356781, reg_loss: 0.05682311868667603), lr: 0.009950347764654375\n",
      "epoch: 600, acc: 0.887, loss: 0.420, (data_loss: 0.3618479371070862, reg_loss: 0.05859713172912598), lr: 0.009940456664579172\n",
      "epoch: 700, acc: 0.850, loss: 0.456, (data_loss: 0.3940895199775696, reg_loss: 0.061523983955383305), lr: 0.009930585209386389\n",
      "epoch: 800, acc: 0.877, loss: 0.407, (data_loss: 0.34434494376182556, reg_loss: 0.062462007522583005), lr: 0.009920733340608539\n",
      "epoch: 900, acc: 0.907, loss: 0.371, (data_loss: 0.30746451020240784, reg_loss: 0.06391456794738769), lr: 0.00991090100000991\n",
      "epoch: 1000, acc: 0.883, loss: 0.370, (data_loss: 0.30487918853759766, reg_loss: 0.06500211906433105), lr: 0.009901088129585442\n",
      "epoch: 1100, acc: 0.900, loss: 0.347, (data_loss: 0.2819884717464447, reg_loss: 0.06542482233047485), lr: 0.00989129467155956\n",
      "epoch: 1200, acc: 0.887, loss: 0.344, (data_loss: 0.27716538310050964, reg_loss: 0.06719441366195679), lr: 0.009881520568385064\n",
      "epoch: 1300, acc: 0.880, loss: 0.392, (data_loss: 0.3223187327384949, reg_loss: 0.06984177446365357), lr: 0.009871765762741982\n",
      "epoch: 1400, acc: 0.913, loss: 0.335, (data_loss: 0.2624981701374054, reg_loss: 0.07211895084381104), lr: 0.009862030197536465\n",
      "epoch: 1500, acc: 0.933, loss: 0.317, (data_loss: 0.24412627518177032, reg_loss: 0.07322273015975952), lr: 0.009852313815899663\n",
      "epoch: 1600, acc: 0.870, loss: 0.413, (data_loss: 0.33797237277030945, reg_loss: 0.07516011142730714), lr: 0.009842616561186627\n",
      "epoch: 1700, acc: 0.870, loss: 0.413, (data_loss: 0.337887167930603, reg_loss: 0.07560269641876222), lr: 0.009832938376975192\n",
      "epoch: 1800, acc: 0.940, loss: 0.285, (data_loss: 0.20941001176834106, reg_loss: 0.0756984748840332), lr: 0.009823279207064904\n",
      "epoch: 1900, acc: 0.933, loss: 0.277, (data_loss: 0.20188656449317932, reg_loss: 0.07494014644622803), lr: 0.009813638995475911\n",
      "epoch: 2000, acc: 0.937, loss: 0.269, (data_loss: 0.1952303946018219, reg_loss: 0.07407874679565431), lr: 0.009804017686447907\n",
      "epoch: 2100, acc: 0.903, loss: 0.313, (data_loss: 0.23720891773700714, reg_loss: 0.07574029159545898), lr: 0.009794415224439025\n",
      "epoch: 2200, acc: 0.940, loss: 0.273, (data_loss: 0.19767218828201294, reg_loss: 0.0756652889251709), lr: 0.009784831554124797\n",
      "epoch: 2300, acc: 0.940, loss: 0.267, (data_loss: 0.19182097911834717, reg_loss: 0.07502016639709473), lr: 0.00977526662039707\n",
      "epoch: 2400, acc: 0.940, loss: 0.261, (data_loss: 0.1871117651462555, reg_loss: 0.07434659099578858), lr: 0.009765720368362972\n",
      "epoch: 2500, acc: 0.940, loss: 0.256, (data_loss: 0.18224479258060455, reg_loss: 0.07373887157440186), lr: 0.009756192743343836\n",
      "epoch: 2600, acc: 0.927, loss: 0.257, (data_loss: 0.18387772142887115, reg_loss: 0.07294504070281982), lr: 0.009746683690874182\n",
      "epoch: 2700, acc: 0.853, loss: 0.504, (data_loss: 0.4300565719604492, reg_loss: 0.07361252403259277), lr: 0.009737193156700649\n",
      "epoch: 2800, acc: 0.947, loss: 0.258, (data_loss: 0.18199525773525238, reg_loss: 0.07589383506774904), lr: 0.009727721086781\n",
      "epoch: 2900, acc: 0.940, loss: 0.250, (data_loss: 0.1754247546195984, reg_loss: 0.07494804382324219), lr: 0.009718267427283064\n",
      "epoch: 3000, acc: 0.943, loss: 0.246, (data_loss: 0.17186817526817322, reg_loss: 0.07411701393127441), lr: 0.009708832124583735\n",
      "epoch: 3100, acc: 0.943, loss: 0.251, (data_loss: 0.17749623954296112, reg_loss: 0.07348172950744629), lr: 0.009699415125267946\n",
      "epoch: 3200, acc: 0.933, loss: 0.250, (data_loss: 0.17700602114200592, reg_loss: 0.0730942039489746), lr: 0.009690016376127677\n",
      "epoch: 3300, acc: 0.877, loss: 0.367, (data_loss: 0.2939144968986511, reg_loss: 0.07271831703186035), lr: 0.00968063582416093\n",
      "epoch: 3400, acc: 0.937, loss: 0.250, (data_loss: 0.17619596421718597, reg_loss: 0.07336639404296875), lr: 0.00967127341657076\n",
      "epoch: 3500, acc: 0.937, loss: 0.239, (data_loss: 0.16589391231536865, reg_loss: 0.07292572784423829), lr: 0.009661929100764258\n",
      "epoch: 3600, acc: 0.937, loss: 0.235, (data_loss: 0.16311430931091309, reg_loss: 0.0718816089630127), lr: 0.009652602824351587\n",
      "epoch: 3700, acc: 0.940, loss: 0.232, (data_loss: 0.16091056168079376, reg_loss: 0.07085027313232423), lr: 0.009643294535144986\n",
      "epoch: 3800, acc: 0.933, loss: 0.279, (data_loss: 0.20919740200042725, reg_loss: 0.07003455352783203), lr: 0.009634004181157814\n",
      "epoch: 3900, acc: 0.917, loss: 0.281, (data_loss: 0.20895978808403015, reg_loss: 0.07218549633026124), lr: 0.009624731710603567\n",
      "epoch: 4000, acc: 0.947, loss: 0.248, (data_loss: 0.17662876844406128, reg_loss: 0.07167010116577148), lr: 0.009615477071894923\n",
      "epoch: 4100, acc: 0.823, loss: 0.704, (data_loss: 0.6309913396835327, reg_loss: 0.0729467077255249), lr: 0.009606240213642783\n",
      "epoch: 4200, acc: 0.957, loss: 0.228, (data_loss: 0.154557466506958, reg_loss: 0.07359450912475586), lr: 0.009597021084655323\n",
      "epoch: 4300, acc: 0.950, loss: 0.224, (data_loss: 0.1510508507490158, reg_loss: 0.07286503982543946), lr: 0.009587819633937046\n",
      "epoch: 4400, acc: 0.950, loss: 0.221, (data_loss: 0.14886607229709625, reg_loss: 0.0719928092956543), lr: 0.009578635810687842\n",
      "epoch: 4500, acc: 0.950, loss: 0.217, (data_loss: 0.14643801748752594, reg_loss: 0.07097718048095703), lr: 0.00956946956430205\n",
      "epoch: 4600, acc: 0.957, loss: 0.214, (data_loss: 0.14445841312408447, reg_loss: 0.06990017318725586), lr: 0.009560320844367537\n",
      "epoch: 4700, acc: 0.950, loss: 0.220, (data_loss: 0.15115459263324738, reg_loss: 0.06876619720458985), lr: 0.009551189600664763\n",
      "epoch: 4800, acc: 0.810, loss: 0.866, (data_loss: 0.794906735420227, reg_loss: 0.07120965099334717), lr: 0.00954207578316587\n",
      "epoch: 4900, acc: 0.937, loss: 0.239, (data_loss: 0.1649966686964035, reg_loss: 0.07383193016052246), lr: 0.009532979342033765\n",
      "epoch: 5000, acc: 0.953, loss: 0.219, (data_loss: 0.14578260481357574, reg_loss: 0.07284908676147461), lr: 0.009523900227621215\n",
      "epoch: 5100, acc: 0.950, loss: 0.215, (data_loss: 0.14349345862865448, reg_loss: 0.07167596435546875), lr: 0.009514838390469937\n",
      "epoch: 5200, acc: 0.950, loss: 0.212, (data_loss: 0.14165200293064117, reg_loss: 0.07065531826019288), lr: 0.009505793781309708\n",
      "epoch: 5300, acc: 0.957, loss: 0.210, (data_loss: 0.14015045762062073, reg_loss: 0.06960452747344971), lr: 0.009496766351057465\n",
      "epoch: 5400, acc: 0.957, loss: 0.208, (data_loss: 0.1397472321987152, reg_loss: 0.06848687648773194), lr: 0.009487756050816422\n",
      "epoch: 5500, acc: 0.877, loss: 0.387, (data_loss: 0.31347471475601196, reg_loss: 0.07354548645019532), lr: 0.009478762831875183\n",
      "epoch: 5600, acc: 0.950, loss: 0.219, (data_loss: 0.14647682011127472, reg_loss: 0.07285660552978517), lr: 0.009469786645706873\n",
      "epoch: 5700, acc: 0.947, loss: 0.216, (data_loss: 0.14345471560955048, reg_loss: 0.0720546989440918), lr: 0.009460827443968249\n",
      "epoch: 5800, acc: 0.950, loss: 0.213, (data_loss: 0.14159174263477325, reg_loss: 0.07105903911590576), lr: 0.009451885178498853\n",
      "epoch: 5900, acc: 0.960, loss: 0.210, (data_loss: 0.13984738290309906, reg_loss: 0.07001052570343018), lr: 0.009442959801320124\n",
      "epoch: 6000, acc: 0.950, loss: 0.208, (data_loss: 0.13950134813785553, reg_loss: 0.06881483840942383), lr: 0.009434051264634572\n",
      "epoch: 6100, acc: 0.953, loss: 0.218, (data_loss: 0.15037785470485687, reg_loss: 0.06766190719604492), lr: 0.009425159520824889\n",
      "epoch: 6200, acc: 0.803, loss: 0.970, (data_loss: 0.9008526802062988, reg_loss: 0.06908232116699219), lr: 0.009416284522453132\n",
      "epoch: 6300, acc: 0.957, loss: 0.217, (data_loss: 0.1465078443288803, reg_loss: 0.07003697586059571), lr: 0.009407426222259851\n",
      "epoch: 6400, acc: 0.950, loss: 0.210, (data_loss: 0.1406230479478836, reg_loss: 0.06911296939849854), lr: 0.009398584573163282\n",
      "epoch: 6500, acc: 0.953, loss: 0.207, (data_loss: 0.13835358619689941, reg_loss: 0.0683609676361084), lr: 0.00938975952825848\n",
      "epoch: 6600, acc: 0.957, loss: 0.205, (data_loss: 0.13741421699523926, reg_loss: 0.06741359901428223), lr: 0.009380951040816517\n",
      "epoch: 6700, acc: 0.950, loss: 0.209, (data_loss: 0.1429014652967453, reg_loss: 0.06647406005859374), lr: 0.009372159064283639\n",
      "epoch: 6800, acc: 0.933, loss: 0.225, (data_loss: 0.1596211940050125, reg_loss: 0.06557242012023926), lr: 0.009363383552280452\n",
      "epoch: 6900, acc: 0.820, loss: 0.775, (data_loss: 0.709261953830719, reg_loss: 0.0661894474029541), lr: 0.009354624458601109\n",
      "epoch: 7000, acc: 0.950, loss: 0.222, (data_loss: 0.15194052457809448, reg_loss: 0.07044930362701417), lr: 0.009345881737212498\n",
      "epoch: 7100, acc: 0.950, loss: 0.207, (data_loss: 0.1369527131319046, reg_loss: 0.07003736782073974), lr: 0.009337155342253428\n",
      "epoch: 7200, acc: 0.953, loss: 0.204, (data_loss: 0.1352638602256775, reg_loss: 0.06905591297149659), lr: 0.009328445228033845\n",
      "epoch: 7300, acc: 0.950, loss: 0.202, (data_loss: 0.13421601057052612, reg_loss: 0.06797586059570312), lr: 0.00931975134903401\n",
      "epoch: 7400, acc: 0.957, loss: 0.200, (data_loss: 0.13324031233787537, reg_loss: 0.06693156433105468), lr: 0.009311073659903723\n",
      "epoch: 7500, acc: 0.957, loss: 0.198, (data_loss: 0.132361501455307, reg_loss: 0.06588383674621581), lr: 0.009302412115461537\n",
      "epoch: 7600, acc: 0.863, loss: 0.611, (data_loss: 0.5424641966819763, reg_loss: 0.06831173038482666), lr: 0.009293766670693966\n",
      "epoch: 7700, acc: 0.953, loss: 0.207, (data_loss: 0.13743473589420319, reg_loss: 0.07001411628723145), lr: 0.009285137280754698\n",
      "epoch: 7800, acc: 0.953, loss: 0.203, (data_loss: 0.13434964418411255, reg_loss: 0.06902810192108154), lr: 0.009276523900963831\n",
      "epoch: 7900, acc: 0.953, loss: 0.201, (data_loss: 0.13316218554973602, reg_loss: 0.06797073364257813), lr: 0.009267926486807106\n",
      "epoch: 8000, acc: 0.957, loss: 0.199, (data_loss: 0.13235588371753693, reg_loss: 0.06685909271240234), lr: 0.00925934499393513\n",
      "epoch: 8100, acc: 0.953, loss: 0.197, (data_loss: 0.1315205842256546, reg_loss: 0.06577783870697021), lr: 0.009250779378162611\n",
      "epoch: 8200, acc: 0.893, loss: 0.407, (data_loss: 0.33956679701805115, reg_loss: 0.06719635772705078), lr: 0.00924222959546761\n",
      "epoch: 8300, acc: 0.957, loss: 0.200, (data_loss: 0.1334676891565323, reg_loss: 0.0668252477645874), lr: 0.009233695601990784\n",
      "epoch: 8400, acc: 0.953, loss: 0.197, (data_loss: 0.13022904098033905, reg_loss: 0.06635434913635253), lr: 0.009225177354034633\n",
      "epoch: 8500, acc: 0.953, loss: 0.194, (data_loss: 0.12912802398204803, reg_loss: 0.06531467628479004), lr: 0.009216674808062748\n",
      "epoch: 8600, acc: 0.950, loss: 0.193, (data_loss: 0.12854436039924622, reg_loss: 0.06430845642089844), lr: 0.009208187920699086\n",
      "epoch: 8700, acc: 0.840, loss: 0.788, (data_loss: 0.7208409309387207, reg_loss: 0.06700829029083252), lr: 0.00919971664872722\n",
      "epoch: 8800, acc: 0.917, loss: 0.356, (data_loss: 0.2862173020839691, reg_loss: 0.06981663608551025), lr: 0.009191260949089605\n",
      "epoch: 8900, acc: 0.953, loss: 0.201, (data_loss: 0.13227437436580658, reg_loss: 0.06864694213867188), lr: 0.009182820778886859\n",
      "epoch: 9000, acc: 0.953, loss: 0.198, (data_loss: 0.13017666339874268, reg_loss: 0.06798322105407714), lr: 0.009174396095377022\n",
      "epoch: 9100, acc: 0.953, loss: 0.196, (data_loss: 0.1289343237876892, reg_loss: 0.067159499168396), lr: 0.00916598685597485\n",
      "epoch: 9200, acc: 0.953, loss: 0.194, (data_loss: 0.12794281542301178, reg_loss: 0.0663163185119629), lr: 0.009157593018251083\n",
      "epoch: 9300, acc: 0.953, loss: 0.192, (data_loss: 0.1270761638879776, reg_loss: 0.06541000366210938), lr: 0.009149214539931748\n",
      "epoch: 9400, acc: 0.950, loss: 0.191, (data_loss: 0.12632158398628235, reg_loss: 0.06448921298980713), lr: 0.009140851378897431\n",
      "epoch: 9500, acc: 0.880, loss: 0.464, (data_loss: 0.3963024914264679, reg_loss: 0.0674328966140747), lr: 0.009132503493182587\n",
      "epoch: 9600, acc: 0.947, loss: 0.198, (data_loss: 0.13038188219070435, reg_loss: 0.06802974796295166), lr: 0.009124170840974827\n",
      "epoch: 9700, acc: 0.953, loss: 0.193, (data_loss: 0.12611393630504608, reg_loss: 0.06713879776000976), lr: 0.009115853380614228\n",
      "epoch: 9800, acc: 0.953, loss: 0.191, (data_loss: 0.1250462532043457, reg_loss: 0.06628167247772217), lr: 0.009107551070592627\n",
      "epoch: 9900, acc: 0.953, loss: 0.190, (data_loss: 0.12442286312580109, reg_loss: 0.06528879928588867), lr: 0.009099263869552954\n",
      "epoch: 10000, acc: 0.950, loss: 0.188, (data_loss: 0.12383367121219635, reg_loss: 0.06423274421691895), lr: 0.009090991736288512\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10001):\n",
    "    # Forward pass\n",
    "    output = dense1.forward(X)\n",
    "    output = relu.forward(output)\n",
    "    output = dense2.forward(output)\n",
    "\n",
    "    # Calculate the network's current loss\n",
    "    data_loss = activation_loss.forward(output, y)\n",
    "    reg_loss = activation_loss.categoricalcrossentropy.regularsiation_loss(dense1) +\\\n",
    "        activation_loss.categoricalcrossentropy.regularsiation_loss(dense2)\n",
    "    loss = data_loss + reg_loss\n",
    "\n",
    "    # Calculate accuracy\n",
    "    predictions = np.argmax(output,axis=1)\n",
    "    if len(y.shape) == 2: y = np.argmax(y,axis=1)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "\n",
    "    # Print accuracy\n",
    "    if not epoch % 100: print(\n",
    "        f\"epoch: {epoch}, acc: {accuracy:.3f}, loss: {loss:.3f}, \"\n",
    "        f\"(data_loss: {data_loss}, reg_loss: {reg_loss}), \"\n",
    "        f\"lr: {optimiser.current_learning_rate}\"\n",
    "    )\n",
    "\n",
    "    # Backward pass\n",
    "    activation_loss.backward(activation_loss.outputs, y)\n",
    "    dense2.backward(activation_loss.dinputs)\n",
    "    relu.backward(dense2.dinputs)\n",
    "    dense1.backward(relu.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimiser.pre_update_params()\n",
    "    optimiser.update_params(dense1)\n",
    "    optimiser.update_params(dense2)\n",
    "    optimiser.post_update_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the validation data set\n",
    "X_test, y_test = spiral_data(samples=100, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass on validation set\n",
    "output = dense1.forward(X_test)\n",
    "output = relu.forward(output)\n",
    "output = dense2.forward(output)\n",
    "\n",
    "# Calculate validation loss\n",
    "loss = activation_loss.forward(output, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation, acc: 0.813, loss: 0.530\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "predictions = np.argmax(output, axis=1)\n",
    "if len(y_test.shape) == 2:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "print(f\"validation, acc: {accuracy:.3f}, loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d485a98a36d7387b9a90aa3c793ce7a86a2239fa29b78a2ccbe0584c0791300d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
